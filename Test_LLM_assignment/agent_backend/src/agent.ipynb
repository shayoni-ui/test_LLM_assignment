{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7266aa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "from azureml.core import Workspace\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fdc10ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27c4fbad0a904765b82b87838210bcec\n",
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/shayonisimms/code\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.identity import DefaultAzureCredential\n",
    "#from azure.keyvault.secrets import SecretClient\n",
    "from azureml.core import Workspace\n",
    " \n",
    "# Load the workspace from config or directly\n",
    "ws = Workspace.from_config()\n",
    "# Access the linked Key Vault\n",
    "keyvault = ws.get_default_keyvault()\n",
    "# Retrieve a secret\n",
    "secret_value = keyvault.get_secret(name=\"flow-ai-id\")\n",
    "secret_id= keyvault.get_secret(name=\"flow-ai-access\")\n",
    "print(secret_value)\n",
    "\n",
    "dir_path = os.getcwd()\n",
    "\n",
    "print(dir_path)\n",
    "\n",
    "main_dir = \"Users/shayoni.x.dutta/Test_LLM_FinCONV\"\n",
    "\n",
    "#MAIN_DIR_PATH = dir_path[:dir_path.index(main_dir)+len(main_dir)]\n",
    "\n",
    "# Your preferred MFlow Model Name\n",
    "MODEL_NAME = \"agent_demo\"\n",
    "\n",
    "# Your secret scope name, change as needed\n",
    "SECRET_SCOPE = \"agents_demo\"  # pragma: allowlist secret\n",
    "\n",
    "# This will pull the current user's USER_NAME for the experiment path\n",
    "#USER_NAME = dir_path.split(\"/\")[dir_path.split(\"/\").index(\"Users\")+1]\n",
    "\n",
    "# Default experiment path, feel free to change as needed\n",
    "##EXPERIMENT_PATH = dir_path[:dir_path.index(USER_NAME)+len(USER_NAME)]+f\"/{MODEL_NAME}_exp\"\n",
    "\n",
    "# Your LLM deployment name\n",
    "DEPLOYMENT_NAME = \"gpt-4\"\n",
    "\n",
    "ARTIFACT_PATH = f\"{MODEL_NAME}_artifact\"\n",
    "\n",
    "credential = DefaultAzureCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22188e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27c4fbad0a904765b82b87838210bcec\n",
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/shayonisimms/code\n"
     ]
    }
   ],
   "source": [
    "# Load the workspace from config or directly\n",
    "ws = Workspace.from_config()\n",
    "# Access the linked Key Vault\n",
    "keyvault = ws.get_default_keyvault()\n",
    "# Retrieve a secret\n",
    "secret_value = keyvault.get_secret(name=\"flow-ai-id\")\n",
    "secret_id= keyvault.get_secret(name=\"flow-ai-access\")\n",
    "print(secret_value)\n",
    "\n",
    "dir_path = os.getcwd()\n",
    "\n",
    "print(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282bee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = \"Users/shayoni.x.dutta/Test_LLM_FinCONV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39286d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your preferred MFlow Model Name\n",
    "MODEL_NAME = \"agent_demo\"\n",
    "\n",
    "# Your LLM deployment name\n",
    "DEPLOYMENT_NAME = \"gpt-4\"\n",
    "\n",
    "ARTIFACT_PATH = f\"{MODEL_NAME}_artifact\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "423b2ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated to workspace: copscscnsus6azmldevtest001 in resource group: codeorange-psc-us6-shared-svc-appresources-devtest at location: eastus2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Authenticated to workspace: {ws.name} in resource group: {ws.resource_group} at location: {ws.location}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "794a12cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variable 'OPENAI_API_VERSION' is set: Soha...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "env_var = \"OPENAI_API_VERSION\"\n",
    "value = os.environ.get(env_var)\n",
    "if value:\n",
    "    print(f\"Environment variable '{env_var}' is set: {value[:4]}...\")  # Masked\n",
    "else:\n",
    "    print(f\"Environment variable '{env_var}' is not set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94b6b234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "Response: {\"access_token\":\"eyJhbGciOiJSUzI1NiIsImtpZCI6Imp3dC1zaWduLWNlcnQtMjAyMyIsIng1dCI6IndqZFNEcTMzRHdSUmM3SkZ1NlBGMWZXOGlTZyIsInBpLmF0bSI6IjZoZjMifQ.eyJzY29wZSI6IiIsImF1dGhvcml6YXRpb25fZGV0YWlscyI6W10sImNsaWVudF9pZCI6IjI3YzRmYmFkMGE5MDQ3NjViODJiODc4MzgyMTBiY2VjIiwiaXNzIjoiaHR0cHM6Ly9mZWRlcmF0aW9uLXFhLmdzay5jb20iLCJhdWQiOiIyN2M0ZmJhZDBhOTA0NzY1YjgyYjg3ODM4MjEwYmNlYyIsImlhdCI6MTc0Nzc0NTgxMCwiZXhwIjoxNzQ3NzYzODEwfQ.UwjJdQwdZ-wV5AjvYh2QrFmPaybCvwXsydCbWcoINxPR0MccQD4PMpozEKZA9DbLwxh03fSqIu868i-yQvopvKRbuE4fggJP7HOHl2RlV0lW0SZg_DjxZMvBi5W2lA23l2BviBZNolkTmo6qsPAPvrIKvdATsHe8D2zPt8pv2Wob9DaOdkVw7ZLA1MWKJEwahUAHNVkkOPy0pvPFIKZ7W3A-0qr801LbkRt6c2cSVLG_ubRi82TESvkRjcCmeLH5d3AyQtCKTfKcCjNDLAh7cHcTnTUo4Ckb8Zw7Vs4M5Y9NqoHayUEvb4PqELT-V07ISgVUod9su_8NEdzg9sU5rA\",\"token_type\":\"Bearer\",\"expires_in\":17999}\n"
     ]
    }
   ],
   "source": [
    "from requests.auth import HTTPBasicAuth\n",
    "import requests\n",
    "\n",
    "data = {\n",
    "    \"grant_type\": \"client_credentials\"\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    \"https://federation-qa.gsk.com/as/token.oauth2\",\n",
    "    auth=HTTPBasicAuth(secret_value, secret_id),\n",
    "    headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n",
    "    data=data\n",
    ")\n",
    "\n",
    "print(\"Status Code:\", response.status_code)\n",
    "print(\"Response:\", response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4306099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTokenProvider:\n",
    "    def __init__(self, access_token):\n",
    "        self.access_token = access_token\n",
    " \n",
    "    def __call__(self, *scopes):\n",
    "        return self.access_token\n",
    " \n",
    " \n",
    "def create_bearer_token():\n",
    " \n",
    "    federation_url = \"https://federation-qa.gsk.com/as/token.oauth2\" # os.getenv(\"federation_url_token\")\n",
    "    client_id = os.environ.get(\"azure_openai_client\") # os.getenv(\"AZURE_CLIENT_ID\")\n",
    "    client_secret = os.environ.get(\"azure_openai_secret\")\n",
    "    grant_type = \"client_credentials\" # os.getenv(\"grant_type_token\")\n",
    " \n",
    "    # Data to send in the request\n",
    "    token_data = {\n",
    "        \"grant_type\": grant_type,\n",
    "        \"client_id\": client_id,\n",
    "        \"client_secret\": client_secret\n",
    "    }\n",
    " \n",
    "    # Request a bearer token\n",
    "    token_response = requests.post(federation_url, data=token_data)\n",
    " \n",
    "    # Extract the access token from the response\n",
    "    if token_response.status_code == 200:\n",
    "        token_info = token_response.json()\n",
    "        access_token = token_info[\"access_token\"]\n",
    "        #print(f\"Access Token: {access_token}\")\n",
    "        return access_token\n",
    "    else:\n",
    "        #print(f\"Failed to get token: {token_response.text}\")\n",
    "        return \"Requst Failed\"\n",
    " \n",
    "# Your existing access token\n",
    "access_token = create_bearer_token()\n",
    " \n",
    "# Create the custom token provider\n",
    "token_provider = CustomTokenProvider(access_token)\n",
    " \n",
    "def model_client():\n",
    " \n",
    "    gpt4o_model_client = AzureOpenAIChatCompletionClient(\n",
    "    model=\"o1\",\n",
    "    azure_endpoint=\"https://dev.api.gsk.com/co/psc/azureopenai/us6/\", # os.getenv(\"o1_AZURE_OPENAI_ENDPOINT\"),\n",
    "    azure_deployment=\"o1\", # os.getenv(\"o1_AZURE_OPENAI_DEPLOYMENT\"),\n",
    "    api_version= \"2024-12-01-preview\", # os.getenv(\"o1_AZURE_OPENAI_API_VERSION\"),\n",
    "    model_capabilities={\"function_calling\": True, \"vision\": True, \"json_output\": True},\n",
    "    azure_ad_token_provider=token_provider\n",
    "    )\n",
    " \n",
    "    return gpt4o_model_client\n",
    "    \n",
    "def create_openai_client():\n",
    "    # Create OpenAI clientCha\n",
    "    client = AzureOpenAI(\n",
    "        api_version= \"2024-12-01-preview\", # os.getenv(\"o1_AZURE_OPENAI_API_VERSION\"),\n",
    "        azure_endpoint=\"https://dev.api.gsk.com/co/psc/azureopenai/us6/\", # os.getenv(\"o1_AZURE_OPENAI_ENDPOINT\"),\n",
    "        azure_ad_token= create_bearer_token(),\n",
    "        max_retries=4\n",
    "    )\n",
    "    return client"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
